{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# üéì Week 1 Mini-Project: Learning Assistant\n",
    "\n",
    "Welcome to your first personal research tool! This assistant will help you master any topic by analyzing multiple data sources and providing answers with clear citations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### 1. Setup & Imports\n",
    "We need to point Python to our `src` folder, which is now **two levels up**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM_PROVIDER: groq\n",
      "EMBEDDING_PROVIDER: local\n",
      "EMBEDDING_MODEL: multi-qa-distilbert-cos-v1\n",
      "VECTOR_SIZE: 768\n",
      "USE_INTELLIGENT_CHUNKING: False\n",
      "Initializing collection: research_documents\n",
      "[OK] Created collection: research_documents\n",
      "‚úÖ Assistant initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path (two levels up from projects/week1_learning_assistant/)\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "\n",
    "from src.utils.config import Config\n",
    "from src.document_loader import DocumentLoader, Document\n",
    "from src.vector_store import VectorStore\n",
    "from groq import Groq\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize components\n",
    "vector_store = VectorStore(in_memory=True)\n",
    "groq_client = Groq(api_key=Config.GROQ_API_KEY)\n",
    "loader = DocumentLoader()\n",
    "\n",
    "print(\"‚úÖ Assistant initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 2. The Ingestion Engine\n",
    "This function handles loading and indexing all your research materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_learning_material(topic: str, sources: dict):\n",
    "    \"\"\"\n",
    "    Ingests research materials for a specific topic.\n",
    "    Sources dict: {\"pdfs\": [], \"webs\": [], \"youtubes\": []}\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Starting Ingestion for Topic: {topic.upper()}\")\n",
    "    \n",
    "    # Clear previous topic data\n",
    "    vector_store.clear()\n",
    "    \n",
    "    all_docs = []\n",
    "    project_root = Config.PROJECT_ROOT\n",
    "\n",
    "        # 1. Process GitHub Repos (Smart Parsing for URLs and Shorthand)\n",
    "    for repo_info in sources.get(\"githubs\", []):\n",
    "        # Clean the input: Remove 'https://github.com/' if it's there\n",
    "        clean_info = repo_info.replace(\"https://github.com/\", \"\").strip(\"/\")\n",
    "        print(\"clean_info\", clean_info)\n",
    "        parts = clean_info.split('/')\n",
    "        print(\"parts\", parts)\n",
    "        \n",
    "        if len(parts) < 2:\n",
    "            print(f\"   ‚ö†Ô∏è Skipping invalid GitHub info: {repo_info}\")\n",
    "            continue\n",
    "            \n",
    "        owner = parts[0]\n",
    "        name = parts[1]\n",
    "        # Use provided branch, or default to 'main'\n",
    "        branch = parts[2] if len(parts) > 2 else \"main\" \n",
    "        \n",
    "        print(f\"   üìÇ Downloading Github Repo: {owner}/{name} (Branch: {branch})\")\n",
    "        repo_docs = loader.load_github_repo(owner, name, branch)\n",
    "        for d in repo_docs:\n",
    "            d.metadata[\"topic\"] = topic\n",
    "        all_docs.extend(repo_docs)\n",
    "    \n",
    "    # Load PDFs\n",
    "    for path in sources.get(\"pdfs\", []):\n",
    "        # Handle relative paths from project root\n",
    "        full_path = os.path.join(project_root, path) if not os.path.isabs(path) else path\n",
    "        if os.path.exists(full_path):\n",
    "            print(f\"   üìÑ Loading PDF: {os.path.basename(full_path)}\")\n",
    "            pdf_pages = loader.load_pdf(full_path)\n",
    "            for p in pdf_pages:\n",
    "                p.metadata[\"topic\"] = topic\n",
    "            all_docs.extend(pdf_pages)\n",
    "            \n",
    "    # Load Web Pages\n",
    "    for url in sources.get(\"webs\", []):\n",
    "        print(f\"   üåê Loading Web: {url}\")\n",
    "        web_doc = loader.load_web_page(url)\n",
    "        web_doc.metadata[\"topic\"] = topic\n",
    "        all_docs.append(web_doc)\n",
    "        \n",
    "    # Load YouTube Transcripts\n",
    "    for url in sources.get(\"youtubes\", []):\n",
    "        print(f\"   üé• Loading YouTube: {url}\")\n",
    "        yt_doc = loader.load_youtube_transcript(url)\n",
    "        yt_doc.metadata[\"topic\"] = topic\n",
    "        all_docs.append(yt_doc)\n",
    "        \n",
    "    if all_docs:\n",
    "        count = vector_store.add_documents(all_docs)\n",
    "        print(f\"\\n‚úÖ Knowledge Base Updated! {count} research chunks ready for '{topic}'.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No materials found to index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 3. Topic Definition\n",
    "Choose a topic and provide your sources here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Ingestion for Topic: DOCKER FUNDAMENTALS\n",
      "Initializing collection: research_documents\n",
      "[OK] Created collection: research_documents\n",
      "[OK] Cleared collection: research_documents\n",
      "clean_info docker/cli/master\n",
      "parts ['docker', 'cli', 'master']\n",
      "   üìÇ Downloading Github Repo: docker/cli (Branch: master)\n",
      "   ‚úÖ Loaded 437 markdown files from GitHub: docker/cli\n",
      "   üìÑ Loading PDF: docker_cheatsheet.pdf\n",
      "   üåê Loading Web: https://docs.docker.com/get-started/overview/\n",
      "   üé• Loading YouTube: https://www.youtube.com/watch?v=fqMOX6JJhGo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d26abb7d3d49b98a5c837c1e8bd141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Added 4135 chunks from 440 documents\n",
      "\n",
      "‚úÖ Knowledge Base Updated! 4135 research chunks ready for 'Docker Fundamentals'.\n"
     ]
    }
   ],
   "source": [
    "MY_TOPIC = \"Docker Fundamentals\"\n",
    "\n",
    "SOURCES = {\n",
    "    \"pdfs\": [\"data/docker_cheatsheet.pdf\"],\n",
    "    \"webs\": [\"https://docs.docker.com/get-started/overview/\"],\n",
    "    \"youtubes\": [\"https://www.youtube.com/watch?v=fqMOX6JJhGo\"],\n",
    "    \"githubs\": [\"docker/cli/master\"], # Example: Indexing the official Docker CLI repo docs\n",
    "}\n",
    "\n",
    "ingest_learning_material(MY_TOPIC, SOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10a3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_assistant(question: str):\n",
    "    \"\"\"\n",
    "    Searches knowledge base and generates answer with clear citations.\n",
    "    \"\"\"\n",
    "    # 1. Search for relevant information\n",
    "    results = vector_store.search(question, top_k=3)\n",
    "    \n",
    "    if not results:\n",
    "        display(Markdown(\"‚ö†Ô∏è *I couldn't find any information about that in your materials.*\"))\n",
    "        return\n",
    "\n",
    "    # 2. Process Context and unique Sources\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for res in results:\n",
    "        context_parts.append(res['text'])\n",
    "        \n",
    "        # Build a citation string\n",
    "        meta = res['metadata']\n",
    "        source_type = meta.get('source_type', 'unknown').upper()\n",
    "        # Find the name from path or url\n",
    "        name = os.path.basename(meta.get('source_path', '')) or meta.get('source_url', 'Web/YouTube')\n",
    "        page = f\" (Page {meta['page_number']})\" if 'page_number' in meta else \"\"\n",
    "        citation = f\"{source_type}: {name}{page}\"\n",
    "        \n",
    "        if citation not in sources:\n",
    "            sources.append(citation)\n",
    "\n",
    "    context_text = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # 3. Ask the AI (Groq)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a professional Learning Assistant. Answer questions accurately using ONLY the provided context. Use bullet points for readability if appropriate.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context_text}\\n\\nQuestion: {question}\"}\n",
    "    ]\n",
    "    \n",
    "    # Standard non-streaming call for simplicity and reliability\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=Config.GROQ_MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # 4. Display the beautiful output\n",
    "    answer = response.choices[0].message.content\n",
    "    display(Markdown(f\"### ü§ñ Assistant Answer\\n{answer}\"))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"üìö SOURCES USED FOR THIS ANSWER:\")\n",
    "    for i, source in enumerate(sources, 1):\n",
    "        print(f\"{i}. {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057323bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Welcome to the Docker Fundamentals Classroom ---\n",
      "(Type 'exit' or 'quit' to finish your session)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ Assistant Answer\n",
       "Here are the benefits of Docker:\n",
       "* Fast and consistent delivery of applications\n",
       "* Streamlines the development lifecycle\n",
       "* Allows developers to work in standardized environments\n",
       "* Enables continuous integration and continuous delivery (CI/CD) workflows\n",
       "* Provides a loosely isolated environment for applications, ensuring security and stability\n",
       "* Enables running many containers simultaneously on a given host\n",
       "* Containers are lightweight and contain everything needed to run the application\n",
       "* No need to rely on what's installed on the host\n",
       "* Enables sharing of containers while working, ensuring everyone gets the same container that works in the same way\n",
       "* Reduces the delay between writing code and running it in production\n",
       "* Allows managing infrastructure in the same ways as managing applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìö SOURCES USED FOR THIS ANSWER:\n",
      "1. WEB: https://docs.docker.com/get-started/overview/\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ Assistant Answer\n",
       "To spin up a Docker container, you can use the following command:\n",
       "\n",
       "```console\n",
       "$ docker run -it <image_name>\n",
       "```\n",
       "\n",
       " Replace `<image_name>` with the name of the image you want to use. For example:\n",
       "\n",
       "```console\n",
       "$ docker run -it alpine\n",
       "```\n",
       "\n",
       "or \n",
       "\n",
       "```console\n",
       "$ docker run -it debian\n",
       "```\n",
       "\n",
       "This will create and start a new container from the specified image, with an interactive shell and a pseudo-TTY attached. \n",
       "\n",
       "Alternatively, you can also specify a name for the container and create it before starting it:\n",
       "\n",
       "```console\n",
       "$ docker container create -i -t --name mycontainer <image_name>\n",
       "$ docker container start --attach -i mycontainer\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìö SOURCES USED FOR THIS ANSWER:\n",
      "1. GITHUB: https://github.com/docker/cli/blob/master/docs/reference/commandline/container_run.md\n",
      "2. GITHUB: https://github.com/docker/cli/blob/master/docs/reference/commandline/container_create.md\n",
      "3. GITHUB: https://github.com/docker/cli/blob/master/docs/reference/commandline/container_attach.md\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "üëã Happy studying! Closing the session.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Welcome to the {MY_TOPIC} Classroom ---\")\n",
    "print(\"(Type 'exit' or 'quit' to finish your session)\\n\")\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"What would you like to learn about? \")\n",
    "    \n",
    "    if user_query.lower() in ['exit', 'quit']:\n",
    "        print(\"\\nüëã Happy studying! Closing the session.\")\n",
    "        break\n",
    "    \n",
    "    if not user_query.strip():\n",
    "        continue\n",
    "        \n",
    "    query_assistant(user_query)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c0682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Research Assistant)",
   "language": "python",
   "name": "ai-assistant-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
